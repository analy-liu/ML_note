- [python爬虫包的介绍与使用](#python爬虫包的介绍与使用)
  - [requests](#requests)
    - [requests.get](#requestsget)
      - [requests.get参数设置](#requestsget参数设置)
      - [requests.get返回值](#requestsget返回值)
  - [lxml](#lxml)
    - [lxml.etree](#lxmletree)
      - [使用xpath获取html文件目标值语法](#使用xpath获取html文件目标值语法)
      - [使用xpath获取html文件目标值例子](#使用xpath获取html文件目标值例子)
  - [selenium](#selenium)
- [解析网页技巧](#解析网页技巧)
  - [突破前端反调试--阻止页面不断debugger](#突破前端反调试--阻止页面不断debugger)
# python爬虫包的介绍与使用
## requests
requests是一个Python第三方库，用于访问网络资源，处理URL资源特别方便  
安装 ：

    pip install requests
### requests.get
#### requests.get参数设置
```python
requests.get(url: str | bytes, params: SupportsItems | Tuple | Iterable | str | bytes | None = ..., **kwargs) -> Response

# 简单使用(只使用url参数)
target_url = 'https://github.com/'
r = requests.get(target_url)

# 进阶使用(使用params参数)
payload = {'key1': 'value1', 'key2': 'value2'}
r = requests.get("'https://www.google.com.hk/search", params=payload)
# r.url的输出为：
# 'https://www.google.com.hk/search?key2=value2&key1=value1'

# 详细使用(使用**kwargs)
proxy = {
    'https': 'https://127.0.0.1:1080',
    'http': 'http://127.0.0.1:1080'
}
header = {
    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36 Edg/88.0.705.68'
## 设置头部信息，代理ip，不使用证书
r = requests.get(target_url, verify=False, headers=header, proxies=proxy) 
```
#### requests.get返回值
返回值通常命名为 r 或 response
|代码|描述|
|:-|:-|
|**r.status_code**|响应状态码|
|**r.raw**|原始响应体，使用r.raw.read()读取|
|**r.content**|字节方式的响应体，需要进行解码|
|**r.content.decode**|("编码格式") 当编码格式与响应头部的字符编码相同时，内容与r.text|
|**r.text**|字符串方式的响应体，会自动更具响应头部的字符编码进行解码|
|**r.headers**|以字典对象储存服务器响应头，但是这个字典比较特殊，字典键不区分大小写，若键不存在，则返回None|
|**r.json()**|request中内置的json解码器|
|**r.raise_for_status()**|请求失败(非200响应)，抛出异常|
|**r.url**|获取请求的url|
|**r.cookies**|获取请求后的cookies|
|**r.encoding**|获取编码格式|
## lxml
lxml是一个Python库，使用它可以轻松处理XML和HTML文件，还可以用于web爬取。  
卸载：

    pip uninstall lxml  
安装：

    python -m pip install lxml -i https://pypi.tuna.tsinghua.edu.cn/simple
### lxml.etree
导入

    from lxml import etree
#### 使用xpath获取html文件目标值语法
```python
# 根据html字符串建立html_xml, 这里使用requests.get的返回值
html_xml = etree.HTML(r.text)
target_element = html_xml.xpath('xpath')
```
#### 使用xpath获取html文件目标值例子
案例html：
```html
<!DOCTYPE html>\n<html lang="zh-CN">
<head>
</head>
<body>
    <ul id="menu" class="menu">
        <li><a title="1" href="https://www.1.com">一</a></li>
        <li><a title="2" href="https://www.2.com">二</a></li>
        <li><a title="3" href="https://www.3.com">三</a></li>
    </ul>
    <ul id="text" class="text">
        <li><a title="1" href="https://www.text1.com">text一</a></li>
        <li><a title="2" href="https://www.text2.com">text二</a></li>
        <li><a title="3" href="https://www.text3.com">text三</a></li>
    </ul>
</body>
</html>
```
```python
#获取id="menu"的ul中的所有href
target_element = html_xml.xpath('\\ul[@id="menu"\li\a\@href')
# 返回
["https://www.1.com"，"https://www.2.com"，"https://www.3.com"]

#获取id="text"的ul中的倒数第二个文本内容
target_element = html_xml.xpath('\\ul[@id="text"\li[last()-1]\a\text()')
# 返回
["text二"]
```
## selenium

# 解析网页技巧
## 突破前端反调试--阻止页面不断debugger
在debugger处添加条件断点，条件为false
参考网站：https://segmentfault.com/a/1190000012359015